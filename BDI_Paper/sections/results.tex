\section{Results}
\label{sec:results}

\subsection{Main Results}

Table~\ref{tab:main_results} and Figure~\ref{fig:main_results} present the overall performance of our BDI-LLM framework across all three PlanBench domains. The framework achieves a combined accuracy of 99.6\% (1,265/1,270), demonstrating near-perfect plan generation with formal verification.

\begin{table}[!htbp]
\centering
\caption{Main results on PlanBench. Accuracy denotes the percentage of instances where the generated plan passes all verification layers (structural, symbolic/VAL, and physics).}
\label{tab:main_results}
\begin{tabular}{lrrrc}
\toprule
\textbf{Domain} & \textbf{Instances} & \textbf{Passed} & \textbf{Failed} & \textbf{Accuracy} \\
\midrule
Blocksworld & 200 & 200 & 0 & 100.0\% \\
Logistics   & 570 & 568 & 2 & 99.6\% \\
Depots      & 500 & 497 & 3 & 99.4\% \\
\midrule
\textbf{Total} & \textbf{1,270} & \textbf{1,265} & \textbf{5} & \textbf{99.6\%} \\
\bottomrule
\end{tabular}
\end{table}

\begin{figure}[!htbp]
\centering
\includegraphics[width=\columnwidth]{figures/main_results.pdf}
\caption{Per-domain accuracy comparison between unverified LLM baselines (GPT-4, from PlanBench) and our BDI-LLM framework. BDI-LLM achieves 65--95 percentage-point improvements across all three domains.}
\label{fig:main_results}
\end{figure}

\FloatBarrier
\subsection{Comparison with Baselines}

Table~\ref{tab:baseline_comparison} and Figure~\ref{fig:main_results} compare our results with previously reported LLM planning baselines on PlanBench. Our framework achieves substantial improvements over all prior results, with the most dramatic gains in Logistics (+94.6 percentage points over the $\sim$5\% baseline) and Blocksworld (+65 percentage points over GPT-4's $\sim$35\%).

\begin{table}[!htbp]
\centering
\caption{Comparison with PlanBench baselines. Prior results are from Valmeekam et al.~\cite{valmeekam2023planbench} using GPT-4 without structured verification.}
\label{tab:baseline_comparison}
\begin{tabular}{lccc}
\toprule
\textbf{Domain} & \textbf{LLM Baseline} & \textbf{BDI-LLM (Ours)} & \textbf{$\Delta$} \\
\midrule
Blocksworld & $\sim$35\% & 100.0\% & +65.0 pp \\
Logistics   & $<$5\%     & 99.6\%  & +94.6 pp \\
Depots      & $<$5\%     & 99.4\%  & +94.4 pp \\
\bottomrule
\end{tabular}
\end{table}

\FloatBarrier
\subsection{Domain-Specific Analysis}

\begin{figure}[!htbp]
\centering
\includegraphics[width=\columnwidth]{figures/complexity_analysis.pdf}
\caption{Relationship between instance complexity (number of goal predicates) and planning success rate. BDI-LLM maintains near-perfect accuracy even at the highest complexity levels across all three domains.}
\label{fig:complexity}
\end{figure}

Figure~\ref{fig:complexity} visualizes the relationship between instance complexity and success across all three domains.

\paragraph{Blocksworld.}
The framework achieves perfect accuracy (200/200) across all complexity levels, from simple 2-goal instances (3 objects) to complex 11-goal instances (12 objects). No VAL repair or structural auto-repair was triggered, indicating that the domain-specific prompt engineering---including bottom-up tower construction ordering, teardown phase generation, and explicit physics constraint enumeration---enables the LLM to generate correct plans on the first attempt. The average generation time is 8.35 seconds, with plan sizes ranging from 4 to 22 action nodes (average 12.2).

\paragraph{Logistics.}
With 568/570 instances solved (99.6\%), Logistics demonstrates the framework's ability to handle complex multi-modal transportation planning. The domain spans a wide complexity range: from single-city, single-package problems (7 objects, 1 goal) to multi-city scenarios with 38 objects and 15 delivery goals. Notably, the framework maintains high accuracy even at the highest complexity levels---all 9 instances with 15 goals and all 17 instances with 12 goals are solved correctly. The VAL repair loop was triggered for 76 instances (13.3\%), successfully repairing 75 of them (98.7\% repair success rate) across 85 total repair attempts. Structural auto-repair was triggered 8 times with 7 successes.

\paragraph{Depots.}
The Depots domain achieves 497/500 (99.4\%) accuracy. All 500 instances share the same object count (18) but vary in goal complexity (1--3 goals). The VAL repair loop was triggered for 35 instances (7.0\%), successfully repairing 32 (91.4\% repair success rate) across 39 total attempts. Structural auto-repair was triggered 5 times, all successful.

\begin{figure}[!htbp]
\centering
\includegraphics[width=\columnwidth]{figures/val_repair.pdf}
\caption{VAL error-driven repair analysis. Left: repair trigger rate and success rate by domain. Right: distribution of repair attempts needed, showing that the majority of repairs succeed on the first attempt.}
\label{fig:val_repair}
\end{figure}

\FloatBarrier
\subsection{VAL Repair Loop Analysis}

Table~\ref{tab:val_repair} and Figure~\ref{fig:val_repair} summarize the error-driven repair loop statistics. The repair mechanism is a critical component: without it, the raw first-attempt accuracy would be lower by approximately 8.4 percentage points (107 additional failures across Logistics and Depots).

\begin{table}[!htbp]
\centering
\caption{VAL error-driven repair loop statistics by domain. ``Triggered'' counts instances where at least one repair attempt was made; ``Success'' counts instances ultimately passing VAL after repair.}
\label{tab:val_repair}
\begin{tabular}{lrrrr}
\toprule
\textbf{Domain} & \textbf{Triggered} & \textbf{Success} & \textbf{Attempts} & \textbf{Rate} \\
\midrule
Blocksworld & 0  & 0  & 0  & --- \\
Logistics   & 76 & 75 & 85 & 98.7\% \\
Depots      & 35 & 32 & 39 & 91.4\% \\
\midrule
\textbf{Total} & \textbf{111} & \textbf{107} & \textbf{124} & \textbf{96.4\%} \\
\bottomrule
\end{tabular}
\end{table}

Table~\ref{tab:repair_attempts} shows the distribution of repair attempts. The majority of repairs succeed on the first attempt, with diminishing returns for subsequent attempts.

\begin{table}[!htbp]
\centering
\caption{Repair success by number of attempts (Logistics + Depots combined).}
\label{tab:repair_attempts}
\begin{tabular}{crr}
\toprule
\textbf{Attempts} & \textbf{Instances} & \textbf{Succeeded} \\
\midrule
1 & 100 & 97 \\
2 & 9   & 8  \\
3 & 2   & 2  \\
\bottomrule
\end{tabular}
\end{table}

\FloatBarrier
\subsection{Failure Analysis}

Table~\ref{tab:failures} details the 5 failed instances. Two distinct failure modes emerge:

\begin{table}[!htbp]
\centering
\caption{Detailed failure analysis for all 5 failed instances.}
\label{tab:failures}
\small
\begin{tabular}{llccp{4.5cm}}
\toprule
\textbf{Instance} & \textbf{Problem} & \textbf{Obj.} & \textbf{Goals} & \textbf{Failure Mode} \\
\midrule
\multicolumn{5}{l}{\textit{Logistics}} \\
instance-166 & logistics-c3-s3-p5-a3 & 18 & 5 & Cycle in plan graph (structural) \\
instance-228 & logistics-c3-s3-p7-a2 & 17 & 7 & Unsatisfied precondition in \texttt{load-airplane}; VAL repair failed \\
\midrule
\multicolumn{5}{l}{\textit{Depots}} \\
instance-173 & depot-3-1-3-4-4-3 & 18 & 2 & Empty plan generated \\
instance-179 & depot-3-1-3-4-4-3 & 18 & 3 & Unsatisfied precondition in \texttt{load} (truck position error); VAL repair failed \\
instance-187 & depot-3-1-3-4-4-3 & 18 & 2 & Unsatisfied precondition in \texttt{load} (truck position error); VAL repair failed \\
\bottomrule
\end{tabular}
\end{table}

\begin{enumerate}
    \item \textbf{Structural failure} (1 instance): The LLM generated a cyclic dependency graph for instance-166 (Logistics), where the plan contained a circular reference among 15 action nodes. This represents a fundamental reasoning error that cannot be repaired by the VAL loop.

    \item \textbf{State tracking errors} (4 instances): The remaining failures involve the LLM losing track of object positions after a sequence of move/drive operations. In instance-228 (Logistics), the model incorrectly assumed an airplane was at a location it had already departed from. In the three Depots failures, the model failed to track truck positions after \texttt{Drive} actions, attempting to \texttt{Load} crates onto trucks at their previous locations. One instance (instance-173) produced an empty plan, suggesting a parsing or generation failure.
\end{enumerate}

\FloatBarrier
\subsection{Generation Time}

Average generation times vary by domain complexity: Blocksworld averages 8.35s per instance, Logistics 15.62s, and Depots 4.59s. The lower Depots time reflects its smaller goal counts (1--3 goals vs.\ up to 15 for Logistics). Maximum generation times reach 49.2s (Blocksworld), 55.4s (Logistics), and 159.8s (Depots, likely due to multiple repair attempts).
