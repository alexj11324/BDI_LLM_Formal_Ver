% Abstract - to be placed in main.tex \begin{abstract}...\end{abstract}
% =========================================================================
% ABSTRACT (copy into main.tex)
% =========================================================================
%
% Large Language Models (LLMs) have demonstrated remarkable natural language
% understanding, yet their ability to generate logically correct multi-step
% plans remains limited---prior work on the PlanBench benchmark reports
% accuracy below 35\% for state-of-the-art models. We present BDI-LLM, a
% neuro-symbolic framework that integrates LLM-based plan generation with
% multi-layer formal verification. Our approach casts the LLM as a
% \emph{generative compiler} within a Belief-Desire-Intention (BDI) agent
% architecture, producing structured plans that are rigorously validated
% through (1)~graph-theoretic structural checks, (2)~PDDL symbolic
% verification via the VAL tool, and (3)~domain-specific physics
% constraints. A closed-loop error-driven repair mechanism re-prompts the
% LLM with concrete VAL error messages and cumulative repair history,
% enabling iterative self-correction. Implemented using the DSPy framework
% for structured LLM programming, our system incorporates domain-specific
% prompt engineering with explicit state tracking, chain-of-symbol
% representations, and verified few-shot demonstrations. Evaluated on 1,270
% PlanBench instances across Blocksworld, Logistics, and Depots, BDI-LLM
% achieves 99.6\% overall accuracy (100\% on Blocksworld, 99.6\% on
% Logistics, 99.4\% on Depots), representing a 65--95 percentage-point
% improvement over unverified LLM baselines.
%
% =========================================================================

\section{Introduction}
\label{sec:introduction}

The ability to generate correct multi-step plans is a fundamental requirement for autonomous agents operating in complex environments. Classical AI planning, grounded in formal representations such as the Planning Domain Definition Language (PDDL)~\cite{mcdermott1998pddl}, provides sound and complete algorithms for plan synthesis. However, these methods require hand-crafted domain models and struggle with the flexibility needed for open-ended, natural language task specifications. Large Language Models (LLMs), by contrast, excel at interpreting natural language instructions and possess broad world knowledge acquired through pre-training, making them attractive candidates for plan generation~\cite{huang2022language,ahn2022saycan}.

Despite this promise, a growing body of evidence demonstrates that LLMs are unreliable planners when used in isolation. Valmeekam et al.~\cite{valmeekam2023planbench} introduced PlanBench, a rigorous benchmark for evaluating LLM planning capabilities, and showed that even GPT-4 achieves only $\sim$35\% accuracy on Blocksworld---a domain with just four operators. Subsequent studies confirm that LLMs struggle with precondition tracking, generate physically impossible action sequences, and fail to maintain state consistency across long action chains~\cite{valmeekam2024llms}. These failures stem from a fundamental mismatch: LLMs perform approximate, pattern-based reasoning, while correct planning demands exact logical inference over state transitions.

Two broad strategies have emerged to address this gap. The first augments the LLM's internal reasoning through advanced prompting techniques such as Chain-of-Thought~\cite{wei2022chain}, Tree of Thoughts~\cite{yao2023tree}, and ReAct~\cite{yao2023react}. While these improve performance on some tasks, they provide no formal guarantees of plan correctness. The second strategy, exemplified by the LLM-Modulo framework~\cite{kambhampati2024llms}, pairs LLMs with external verifiers that check generated plans against formal specifications. This neuro-symbolic approach is more principled, but existing instantiations typically employ a single verification layer and lack systematic mechanisms for error-driven plan repair.

In this paper, we present \textbf{BDI-LLM}, a neuro-symbolic planning framework that bridges LLM-based generation and formal verification through a multi-layer architecture grounded in the Belief-Desire-Intention (BDI) agent model~\cite{rao1995bdi}. Our framework treats the LLM as a \emph{generative compiler}: given beliefs (current world state) and desires (goal specification), it produces structured intentions (plans) represented as directed acyclic graphs of actions. These plans are then subjected to three layers of verification---structural, symbolic, and physics-based---with a closed-loop repair mechanism that feeds concrete error diagnostics back to the LLM for iterative correction (Figure~\ref{fig:architecture}).

Our approach makes the following contributions:

\begin{enumerate}
    \item \textbf{Multi-layer verification architecture.} We propose a three-layer verification pipeline combining graph-theoretic structural validation, PDDL symbolic verification via the VAL tool~\cite{howey2004val}, and domain-specific physics constraints. Each layer catches a distinct class of errors, from malformed graph structures to violated action preconditions.

    \item \textbf{Error-driven repair loop.} We introduce a closed-loop repair mechanism that re-prompts the LLM with specific VAL error messages and cumulative repair history. This enables targeted self-correction: the LLM receives not just a pass/fail signal, but precise diagnostic information about \emph{which} preconditions were violated and \emph{at which} step, achieving a 96.4\% repair success rate.

    \item \textbf{Domain-specific structured prompting.} We develop domain-tailored DSPy signatures~\cite{khattab2023dspy} that incorporate explicit state tracking tables, chain-of-symbol representations, check-before-act protocols, and verified few-shot demonstrations derived from actual VAL validation traces. These prompts encode domain constraints (e.g., airport identification in Logistics, hoist availability in Depots) directly into the generation process.

    \item \textbf{State-of-the-art PlanBench results.} Evaluated on 1,270 instances across three PlanBench domains, BDI-LLM achieves 99.6\% overall accuracy---100\% on Blocksworld (200 instances), 99.6\% on Logistics (570 instances), and 99.4\% on Depots (500 instances). This represents a 65--95 percentage-point improvement over prior unverified LLM baselines.
\end{enumerate}

The remainder of this paper is organized as follows. Section~\ref{sec:related_work} surveys related work on LLM planning, formal verification, and BDI architectures. Section~\ref{sec:method} describes our framework architecture and key design decisions. Section~\ref{sec:experiments} details the experimental setup. Section~\ref{sec:results} presents results and analysis. Section~\ref{sec:discussion} discusses implications and limitations, and Section~\ref{sec:conclusion} concludes.
